{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataFunctions\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall idea of simulation: Do pairings taking into consideration current score (win-lose rate) and their geographical location. It will use an adaptation of the Swiss Pairing System, the main difference is that instead of participants having a ELO score or rating and being paired by it; we consider an objective function on the total distance travelled and find proper pairings that minimize it. \n",
    "\n",
    "Tentative Objective function: $\\sum (d_i)^2 + max(d_i)^2$. This function uses L2 norm and a L2 regularization term. We have to consider a regularization term as it helps us to avoid having multiple low distances and 1 large distance. For simplicity we can remove the regularization to trial the algorithm, and then regularization.\n",
    "\n",
    "Rules per each round:\n",
    "1. Split teams by their current score (#wins)\n",
    "2. Pair from highest scoring group to lowest scoring group.\n",
    "3. Per each group, find the group of pairs that minimize the objective function.\n",
    "4. If there are odd # of teams, demote unpaired team into next scoring group. If it has been demoted before, use the next possible pairing that includes that team.\n",
    "5. If there exist unpaired teams, demote them into the next scoring group. \n",
    "6. After making all possible pairings, set distance of teams that are playing together to inf.\n",
    "7. For each pairing, if both teams have the same # of home games, pick one to be home and one to be away randomly. If one team has more # home games than the other, pick the team with the least # home games to be home, the other to be the away.\n",
    "\n",
    "Things to store in db:\n",
    "1. Each team 2022 stats.\n",
    "2. Each team # (from 0 to 131).\n",
    "3. Simulated season pairings, w-l record and h-a count.\n",
    "4. Simulated games and scores.\n",
    "\n",
    "Simulating each pairing:\n",
    "1. Use 2022 stats to predict a spread and totalpts. We use those as means.\n",
    "2. Using a normal distribution on the spread and totalpts with the standard deviation found on the model. We randomly generate a result with the simulated spread and totalpts.\n",
    "3. We use obtained values to create an score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 6.788, 2.244, 2.021, 2.417, 9.85 , 6.086, 4.629, 4.285],\n",
       "       [6.788, 0.   , 4.858, 5.37 , 9.09 , 8.252, 7.448, 2.895, 1.733],\n",
       "       [2.244, 4.858, 0.   , 3.481, 2.494, 8.776, 9.597, 9.295, 8.486],\n",
       "       [2.021, 5.37 , 3.481, 0.   , 3.004, 6.085, 1.993, 8.578, 7.354],\n",
       "       [2.417, 9.09 , 2.494, 3.004, 0.   , 7.754, 8.941, 6.631, 3.278],\n",
       "       [9.85 , 8.252, 8.776, 6.085, 7.754, 0.   , 6.64 , 6.646, 1.713],\n",
       "       [6.086, 7.448, 9.597, 1.993, 8.941, 6.64 , 0.   , 6.429, 1.202],\n",
       "       [4.629, 2.895, 9.295, 8.578, 6.631, 6.646, 6.429, 0.   , 1.547],\n",
       "       [4.285, 1.733, 8.486, 7.354, 3.278, 1.713, 1.202, 1.547, 0.   ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating random distance matrix of size = 8\n",
    "nteams = 9\n",
    "\n",
    "m_dist = np.around(np.random.uniform(1,10,size=(nteams,nteams)),decimals=3)\n",
    "\n",
    "for i in range(nteams):\n",
    "    for j in range(nteams):\n",
    "        m_dist[j,i]=m_dist[i,j]\n",
    "    m_dist[i,i]=0\n",
    "\n",
    "m_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 0],\n",
       "       [2, 0],\n",
       "       [3, 0],\n",
       "       [4, 0],\n",
       "       [5, 0],\n",
       "       [6, 0],\n",
       "       [7, 0],\n",
       "       [8, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#storing wins per team.\n",
    "curr_data = np.zeros(shape=(nteams,2),dtype=int)\n",
    "curr_data[:,0] = np.arange(nteams)\n",
    "curr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting in groups\n",
    "sim1group0 = np.array([x[0].astype(int) for x in curr_data if x[1]==0])\n",
    "# sim1group1 = [[x[0].astype(int),0] for x in curr_data if x[1]==1]\n",
    "sim1group0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot find all pairs and run for all of them. That operation has time complexity O(n!) and for 130ish teams is not feasible as it is about $10^{220}$. We need to use another approach.<br>\n",
    "Fastest approach is done by sorting all possible distances, then picking the suitable one and remove unsuitables from the list. We only need to sort once since at the beginning all teams have to play. We should also count the # of possible matches and use that to do the sorting as well.<br><br>\n",
    "\n",
    "Algorithm procedure using networkx and Blossom algorithm (also known as Edmonds' algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = []\n",
    "Gs1g0 = nx.Graph()\n",
    "\n",
    "for i in sim1group0:\n",
    "    for j in sim1group0:\n",
    "        if i<j: \n",
    "            L.append((i,j,m_dist[i,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gs1g0.add_weighted_edges_from(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeDataView([(0, 1, 6.788), (0, 2, 2.244), (0, 3, 2.021), (0, 4, 2.417), (0, 5, 9.85), (0, 6, 6.086), (0, 7, 4.629), (0, 8, 4.285), (1, 2, 4.858), (1, 3, 5.37), (1, 4, 9.09), (1, 5, 8.252), (1, 6, 7.448), (1, 7, 2.895), (1, 8, 1.733), (2, 3, 3.481), (2, 4, 2.494), (2, 5, 8.776), (2, 6, 9.597), (2, 7, 9.295), (2, 8, 8.486), (3, 4, 3.004), (3, 5, 6.085), (3, 6, 1.993), (3, 7, 8.578), (3, 8, 7.354), (4, 5, 7.754), (4, 6, 8.941), (4, 7, 6.631), (4, 8, 3.278), (5, 6, 6.64), (5, 7, 6.646), (5, 8, 1.713), (6, 7, 6.429), (6, 8, 1.202), (7, 8, 1.547)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gs1g0.edges.data(\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchings1g0 = nx.algorithms.matching.min_weight_matching(Gs1g0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 7), (2, 4), (0, 3), (8, 6)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(matchings1g0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.021, 2.895, 2.494, 1.202)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking \n",
    "m_dist[0,3],m_dist[1,7],m_dist[2,4],m_dist[8,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.202,\n",
       " 1.547,\n",
       " 1.713,\n",
       " 1.733,\n",
       " 1.993,\n",
       " 2.021,\n",
       " 2.244,\n",
       " 2.417,\n",
       " 2.494,\n",
       " 2.895,\n",
       " 3.004,\n",
       " 3.278,\n",
       " 3.481,\n",
       " 4.285,\n",
       " 4.629,\n",
       " 4.858,\n",
       " 5.37,\n",
       " 6.085,\n",
       " 6.086,\n",
       " 6.429,\n",
       " 6.631,\n",
       " 6.64,\n",
       " 6.646,\n",
       " 6.788,\n",
       " 7.354,\n",
       " 7.448,\n",
       " 7.754,\n",
       " 8.252,\n",
       " 8.486,\n",
       " 8.578,\n",
       " 8.776,\n",
       " 8.941,\n",
       " 9.09,\n",
       " 9.295,\n",
       " 9.597,\n",
       " 9.85]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LS = sorted(np.array(L)[:,2])\n",
    "LS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
